{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import json\n",
    "import csv\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import lmdb\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, Dataset, DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use MPS (Apple GPU) if available; otherwise, fall back to CPU\n",
    "DEVICE = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "#DEVICE = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using consolidated training data\n",
    "1. Legibility\n",
    "2. Digit classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to create merged ground truths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths (update these as needed)\n",
    "txt_file_path = \"./data/SoccerNetLegibility/train/train_gt.txt\" #legibility ground truth (frame level)\n",
    "json_file_path = \"./data/train_gt_numbers.json\" #numbers ground truth (tracklet level)\n",
    "output_file_path = \"./data/merged_ground_truths.csv\"\n",
    "\n",
    "# Step 1: Load legibility ground truths from TXT file\n",
    "legibility_data = {}\n",
    "\n",
    "with open(txt_file_path, \"r\") as txt_file:\n",
    "    for line in txt_file:\n",
    "        parts = line.strip().split(\",\")\n",
    "        frame_name = parts[0].strip(\".jpg\")  # Format: trackletID_frameID.jpg\n",
    "        legibility = int(parts[1])  # 0 or 1\n",
    "        legibility_data[frame_name] = legibility\n",
    "\n",
    "# Step 2: Load jersey number ground truths from JSON file\n",
    "with open(json_file_path, \"r\") as json_file:\n",
    "    jersey_numbers = json.load(json_file)  # Dictionary: {\"trackletID\": jersey_number}\n",
    "\n",
    "# Step 3: Merge data and write to output file\n",
    "with open(output_file_path, \"w\") as output_file:\n",
    "    for frame_name, legibility in legibility_data.items():\n",
    "        tracklet_id = frame_name.split(\"_\")[0]  # Extract tracklet number\n",
    "        jersey_number = jersey_numbers.get(tracklet_id, -1)  # Default to -1 if not found\n",
    "        output_file.write(f\"{frame_name}, {legibility}, {jersey_number}\\n\")\n",
    "\n",
    "print(f\"Merged ground truths saved to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(128),      # Resize the smaller edge while keeping aspect ratio\n",
    "    transforms.CenterCrop(128),  # Ensures final size\n",
    "    transforms.ToTensor()       # Convert to PyTorch tensor (C, H, W)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading ground truths\n",
    "# For each cropped jersey number image (named as <tracklet>_<frame>.jpg), it extracts the <tracklet> part from the name   \n",
    "# and looks up its ground truth in the JSON file, loads the image, performs transformations, and appends it to a list.\n",
    "\n",
    "def load_merged_data(img_dir=\"./data/SoccerNetLegibility/train/images\", gt_file=\"./data/merged_ground_truths.csv\"):\n",
    "    # Load the ground truths into a dictionary\n",
    "    gt_data = {}\n",
    "\n",
    "    with open(gt_file, \"r\") as csv_file:\n",
    "        reader = csv.reader(csv_file)\n",
    "        for row in reader:\n",
    "            frame_id = row[0].strip()  # tracklet_number_frame_id\n",
    "            legibility = int(row[1].strip())  # 0 or 1\n",
    "            jersey_number = int(row[2].strip())  # -1 or 1 to 99\n",
    "            gt_data[frame_id] = (legibility, jersey_number)\n",
    "\n",
    "\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    for filename in os.listdir(img_dir):\n",
    "        if filename.endswith(\".jpg\"):\n",
    "            # key = filename.split(\"_\")[0]  # Extract tracklet ID from filename\n",
    "            # label = gt_data[key]\n",
    "\n",
    "            img_path = os.path.join(img_dir, filename)\n",
    "            try:\n",
    "                img = Image.open(img_path).convert(\"RGB\")  \n",
    "                img_tensor = transform(img)  \n",
    "            except Exception as e:\n",
    "                print(f\"Error loading image {img_path}: {e}\")\n",
    "                continue \n",
    "            \n",
    "            images.append(img_tensor)\n",
    "\n",
    "            key = filename.split(\".\")\n",
    "            label = gt_data[key[0]]\n",
    "\n",
    "            # we use separate labels for legibility and jersey number (so the model will have to output them separately)\n",
    "            if label[1] == -1 or label[0] == 0:\n",
    "                labels.append([0, 0])   \n",
    "            else:\n",
    "                labels.append(label)\n",
    "\n",
    "    \n",
    "    return torch.stack(images), torch.tensor(labels, dtype=torch.long)  # return Tensors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images and labels from merged_ground_truths.csv file for single-loss\n",
    "def load_data_csv(img_dir=\"./data/SoccerNetLegibility/train/images\", gt_file=\"./data/merged_ground_truths.csv\"):\n",
    "    # Load the ground truths into a dictionary\n",
    "    gt_data = {}\n",
    "\n",
    "    with open(gt_file, \"r\") as csv_file:\n",
    "        reader = csv.reader(csv_file)\n",
    "        for row in reader:\n",
    "            frame_id = row[0].strip()  # tracklet_number_frame_id\n",
    "            jersey_number = int(row[2].strip())  # -1 or 1 to 99\n",
    "            gt_data[frame_id] = jersey_number\n",
    "\n",
    "\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    for filename in os.listdir(img_dir):\n",
    "        if filename.endswith(\".jpg\"):\n",
    "            # key = filename.split(\"_\")[0]  # Extract tracklet ID from filename\n",
    "            # label = gt_data[key]\n",
    "\n",
    "            img_path = os.path.join(img_dir, filename)\n",
    "            try:\n",
    "                img = Image.open(img_path).convert(\"RGB\")  \n",
    "                img_tensor = transform(img)  \n",
    "            except Exception as e:\n",
    "                print(f\"Error loading image {img_path}: {e}\")\n",
    "                continue \n",
    "            \n",
    "            images.append(img_tensor)\n",
    "\n",
    "            key = filename.split(\".\")\n",
    "            label = gt_data[key[0]]\n",
    "\n",
    "            if label[1] == -1:\n",
    "                labels.append(0)   \n",
    "            else:\n",
    "                labels.append(label)\n",
    "\n",
    "    \n",
    "    return torch.stack(images), torch.tensor(labels, dtype=torch.long)  # return Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images and labels in the format: <legibility>, <jersey number>\n",
    "# images, labels = load_merged_data()\n",
    "\n",
    "# Load images just using the number as the ground truth:\n",
    "images, labels = load_data_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(images, labels)\n",
    "\n",
    "# 95-5 train-test split\n",
    "train_size = int(0.95 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# For initial model testing, try to overfit to a small subset of the training data to see if the model has sufficient complexity\n",
    "small_train_size = int(0.15 * len(train_dataset))\n",
    "small_indices = random.sample(range(len(train_dataset)), small_train_size)\n",
    "small_train_dataset = torch.utils.data.Subset(train_dataset, small_indices)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
    "small_train_loader = DataLoader(small_train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
    "\n",
    "print(f\"Total dataset size: {len(dataset)}\")\n",
    "print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "print(f\"Test dataset size: {len(test_dataset)}\")\n",
    "print(f\"Small test dataset size: {len(small_train_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JerseyNumberClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(JerseyNumberClassifier, self).__init__()\n",
    "        \n",
    "        # 64x64 input\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        \n",
    "        # 32x32 inputs\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        \n",
    "        # 16x16 inputs\n",
    "        self.block3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        \n",
    "        # 8x8 inputs \n",
    "        self.block4 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        \n",
    "        # 4x4 inputs\n",
    "        self.block5 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "        # 2x2 inputs\n",
    "        self.block6 = nn.Sequential(\n",
    "            nn.Conv2d(512, 1024, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(1024, 1024, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        \n",
    "        # 1x1 inputs\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(1024 * 1 * 1, 8192),   # output of last conv block is 1024 * 1 * 1\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8192, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4096, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 100)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.block4(x)\n",
    "        x = self.block5(x)\n",
    "        x = self.block6(x)\n",
    "        x = torch.flatten(x, start_dim=1)  \n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
